from py4godot.utils.VariantTypeWrapper4 import *
import py4godot.classes.Object as __object__
from typing import Any

import py4godot.classes.core as __core__
from py4godot.signals import BuiltinSignal
import py4godot.classes.OpenXRInterface as __openxrinterface__
import py4godot.classes.RefCounted as __refcounted__
import py4godot.classes.MobileVRInterface as __mobilevrinterface__
import py4godot.classes.XRInterfaceExtension as __xrinterfaceextension__
import py4godot.classes.XRInterface as __xrinterface__
import py4godot.classes.WebXRInterface as __webxrinterface__


class Capabilities:
  XR_NONE:int = 0
  XR_MONO:int = 1
  XR_STEREO:int = 2
  XR_QUAD:int = 4
  XR_VR:int = 8
  XR_AR:int = 16
  XR_EXTERNAL:int = 32
class TrackingStatus:
  XR_NORMAL_TRACKING:int = 0
  XR_EXCESSIVE_MOTION:int = 1
  XR_INSUFFICIENT_FEATURES:int = 2
  XR_UNKNOWN_TRACKING:int = 3
  XR_NOT_TRACKING:int = 4
class PlayAreaMode:
  XR_PLAY_AREA_UNKNOWN:int = 0
  XR_PLAY_AREA_3DOF:int = 1
  XR_PLAY_AREA_SITTING:int = 2
  XR_PLAY_AREA_ROOMSCALE:int = 3
  XR_PLAY_AREA_STAGE:int = 4
class EnvironmentBlendMode:
  XR_ENV_BLEND_MODE_OPAQUE:int = 0
  XR_ENV_BLEND_MODE_ADDITIVE:int = 1
  XR_ENV_BLEND_MODE_ALPHA_BLEND:int = 2


class XRInterface(__refcounted__.RefCounted):
  """
		This class needs to be implemented to make an AR or VR platform available to Godot and these should be implemented as C++ modules or GDExtension modules. Part of the interface is exposed to GDScript so you can detect, enable and configure an AR or VR platform.
		Interfaces should be written in such a way that simply enabling them will give us a working setup. You can query the available interfaces through `XRServer`.
	"""
  play_area_changed: BuiltinSignal

  @staticmethod
  def constructor()->XRInterface:pass



  @staticmethod
  def cast(other:__object__.Object)->XRInterface:pass


  @property
  def interface_is_primary(self)->bool:
    """"""
    pass
  @interface_is_primary.setter
  def interface_is_primary(self,  value:bool)->None:
    """"""
    pass
  @property
  def xr_play_area_mode(self)->int:
    """"""
    pass
  @xr_play_area_mode.setter
  def xr_play_area_mode(self,  value:int)->None:
    """"""
    pass
  @property
  def environment_blend_mode(self)->int:
    """"""
    pass
  @environment_blend_mode.setter
  def environment_blend_mode(self,  value:int)->None:
    """"""
    pass
  @property
  def ar_is_anchor_detection_enabled(self)->bool:
    """"""
    pass
  @ar_is_anchor_detection_enabled.setter
  def ar_is_anchor_detection_enabled(self,  value:bool)->None:
    """"""
    pass
  def get_name(self)->__core__.StringName:
    """
				Returns the name of this interface (`"OpenXR"`, `"OpenVR"`, `"OpenHMD"`, `"ARKit"`, etc.).
			"""
    pass

  def get_capabilities(self)->int:
    """
				Returns a combination of `enum Capabilities` flags providing information about the capabilities of this interface.
			"""
    pass

  def is_primary(self)->bool:
    """"""
    pass

  def set_primary(self, primary:bool)->None:
    """"""
    pass

  def is_initialized(self)->bool:
    """
				Returns `true` if this interface has been initialized.
			"""
    pass

  def initialize(self)->bool:
    """
				Call this to initialize this interface. The first interface that is initialized is identified as the primary interface and it will be used for rendering output.
				After initializing the interface you want to use you then need to enable the AR/VR mode of a viewport and rendering should commence.
				**Note:** You must enable the XR mode on the main viewport for any device that uses the main output of Godot, such as for mobile VR.
				If you do this for a platform that handles its own output (such as OpenVR) Godot will show just one eye without distortion on screen. Alternatively, you can add a separate viewport node to your scene and enable AR/VR on that viewport. It will be used to output to the HMD, leaving you free to do anything you like in the main window, such as using a separate camera as a spectator camera or rendering something completely different.
				While currently not used, you can activate additional interfaces. You may wish to do this if you want to track controllers from other platforms. However, at this point in time only one interface can render to an HMD.
			"""
    pass

  def uninitialize(self)->None:
    """
				Turns the interface off.
			"""
    pass

  def get_system_info(self)->__core__.Dictionary:
    """
				Returns a `Dictionary` with extra system info. Interfaces are expected to return `XRRuntimeName` and `XRRuntimeVersion` providing info about the used XR runtime. Additional entries may be provided specific to an interface.
				**Note:**This information may only be available after `initialize` was successfully called.
			"""
    pass

  def get_tracking_status(self)->int:
    """
				If supported, returns the status of our tracking. This will allow you to provide feedback to the user whether there are issues with positional tracking.
			"""
    pass

  def get_render_target_size(self)->__core__.Vector2:
    """
				Returns the resolution at which we should render our intermediate results before things like lens distortion are applied by the VR platform.
			"""
    pass

  def get_view_count(self)->int:
    """
				Returns the number of views that need to be rendered for this device. 1 for Monoscopic, 2 for Stereoscopic.
			"""
    pass

  def trigger_haptic_pulse(self, action_name:str, tracker_name:__core__.StringName|str, frequency:float, amplitude:float, duration_sec:float, delay_sec:float)->None:
    """
				Triggers a haptic pulse on a device associated with this interface.
				`action_name` is the name of the action for this pulse.
				`tracker_name` is optional and can be used to direct the pulse to a specific device provided that device is bound to this haptic.
				`frequency` is the frequency of the pulse, set to `0.0` to have the system use a default frequency.
				`amplitude` is the amplitude of the pulse between `0.0` and `1.0`.
				`duration_sec` is the duration of the pulse in seconds.
				`delay_sec` is a delay in seconds before the pulse is given.
			"""
    pass

  def supports_play_area_mode(self, mode:int )->bool:
    """
				Call this to find out if a given play area mode is supported by this interface.
			"""
    pass

  def get_play_area_mode(self)->int:
    """"""
    pass

  def set_play_area_mode(self, mode:int )->bool:
    """
				Sets the active play area mode, will return `false` if the mode can't be used with this interface.
				**Note:** Changing this after the interface has already been initialized can be jarring for the player, so it's recommended to recenter on the HMD with `XRServer.center_on_hmd` (if switching to `constant XRInterface.XR_PLAY_AREA_STAGE`) or make the switch during a scene change.
			"""
    pass

  def get_play_area(self)->__core__.PackedVector3Array:
    """
				Returns an array of vectors that represent the physical play area mapped to the virtual space around the `XROrigin3D` point. The points form a convex polygon that can be used to react to or visualize the play area. This returns an empty array if this feature is not supported or if the information is not yet available.
			"""
    pass

  def get_anchor_detection_is_enabled(self)->bool:
    """"""
    pass

  def set_anchor_detection_is_enabled(self, enable:bool)->None:
    """"""
    pass

  def get_camera_feed_id(self)->int:
    """
				If this is an AR interface that requires displaying a camera feed as the background, this method returns the feed ID in the `CameraServer` for this interface.
			"""
    pass

  def is_passthrough_supported(self)->bool:
    """
				Returns `true` if this interface supports passthrough.
			"""
    pass

  def is_passthrough_enabled(self)->bool:
    """
				Returns `true` if passthrough is enabled.
			"""
    pass

  def start_passthrough(self)->bool:
    """
				Starts passthrough, will return `false` if passthrough couldn't be started.
				**Note:** The viewport used for XR must have a transparent background, otherwise passthrough may not properly render.
			"""
    pass

  def stop_passthrough(self)->None:
    """
				Stops passthrough.
			"""
    pass

  def get_transform_for_view(self, view:int, cam_transform:__core__.Transform3D)->__core__.Transform3D:
    """
				Returns the transform for a view/eye.
				`view` is the view/eye index.
				`cam_transform` is the transform that maps device coordinates to scene coordinates, typically the `Node3D.global_transform` of the current XROrigin3D.
			"""
    pass

  def get_projection_for_view(self, view:int, aspect:float, near:float, far:float)->__core__.Projection:
    """
				Returns the projection matrix for a view/eye.
			"""
    pass

  def get_supported_environment_blend_modes(self)->__core__.Array:
    """
				Returns the an array of supported environment blend modes, see `enum XRInterface.EnvironmentBlendMode`.
			"""
    pass

  def set_environment_blend_mode(self, mode:int )->bool:
    """
				Sets the active environment blend mode.
				`mode` is the environment blend mode starting with the next frame.
				**Note:** Not all runtimes support all environment blend modes, so it is important to check this at startup. For example:
				```gdscript
				func _ready():
					var xr_interface = XRServer.find_interface("OpenXR")
					if xr_interface and xr_interface.is_initialized():
						var vp = get_viewport()
						vp.use_xr = true
						var acceptable_modes = `XRInterface.XR_ENV_BLEND_MODE_OPAQUE, XRInterface.XR_ENV_BLEND_MODE_ADDITIVE`
						var modes = xr_interface.get_supported_environment_blend_modes()
						for mode in acceptable_modes:
							if mode in modes:
								xr_interface.set_environment_blend_mode(mode)
								break
				```
			"""
    pass

  def get_environment_blend_mode(self)->int:
    """"""
    pass


